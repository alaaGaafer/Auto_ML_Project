{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bestmodel import *\n",
    "from cashAlgorithm.smacClass import ProblemType\n",
    "from cashAlgorithm.Models import SARIMAModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # url = \"https://www.openml.org/data/get_csv/31/dataset_31.csv\"\n",
    "# url='data.csv'\n",
    "# df = pd.read_csv(url)\n",
    "# #export the data to a csv file\n",
    "# # df.to_csv('data.csv', index=False)\n",
    "# df = df.dropna()\n",
    "\n",
    "# # Convert categorical features to numerical\n",
    "# df = pd.get_dummies(df, drop_first=True)\n",
    "# target = \"class_good\"\n",
    "# # X = df.drop(columns=target)\n",
    "# y = df[target]\n",
    "\n",
    "# X_train_raw, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# def Which_features(X_train,y_train,number_of_columns):\n",
    "\n",
    "#     # Select the top k features based on ANOVA F-statistic\n",
    "#     selector = SelectKBest(score_func=f_classif, k=number_of_columns)\n",
    "#     X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "#     # Get the column names of the selected features\n",
    "#     selected_feature_names = X_train.columns[selector.get_support()]\n",
    "\n",
    "    \n",
    "#     return list(selected_feature_names)\n",
    "\n",
    "# selected_features = Which_features(X_train_raw,y_train,number_of_columns=15)\n",
    "# X =X[selected_features]\n",
    "# X_train_raw = X_train_raw[selected_features]\n",
    "# X_test = X_test[selected_features]\n",
    "# # selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #try svc with linear kernel and on datasetabove\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# svcobj = SVC(kernel='linear')\n",
    "# svcobj.fit(X_train_raw, y_train)\n",
    "# y_pred = svcobj.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# #testsvm, test regression, test time series\n",
    "# if __name__ == '__main__':\n",
    "#     problemtype = ProblemType.CLASSIFICATION\n",
    "#     choosenModels=['KNN','LR']\n",
    "#     Bestmodelobj = Bestmodel(problemtype,choosenModels,X_train_raw,X_test,y_train,y_test)\n",
    "#     Bestmodelobj.splitTestData()\n",
    "#     Bestmodelobj.TrainModel()\n",
    "#     predictions=Bestmodelobj.PredictModel(X_test)\n",
    "#     print(Bestmodelobj.modelobj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn import datasets\n",
    "# iris = datasets.load_iris()\n",
    "\n",
    "# X = iris.data[:, 1:]\n",
    "# y = iris.data[:, 0] \n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ['LinearRegression','Lasso','Ridge','RF','XGboost']\n",
    "# if __name__ == \"__main__\":\n",
    "#     problemtype = ProblemType.REGRESSION\n",
    "#     choosenModels=['LR','Lasso','Ridge','RF','XGboost']\n",
    "#     Bestmodelobj = Bestmodel(problemtype,choosenModels,X_train,X_test,y_train,y_test)\n",
    "#     Bestmodelobj.splitTestData()\n",
    "#     Bestmodelobj.TrainModel()\n",
    "#     predictions=Bestmodelobj.PredictModel(X_test)\n",
    "#     print(Bestmodelobj.modelobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similaritySearch.functions import *\n",
    "from bestmodel import *\n",
    "from cashAlgorithm.smacClass import ProblemType\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def calculate_date_frequency(series):\n",
    "    \"\"\"\n",
    "    Calculate the most common frequency (interval) of a datetime series.\n",
    "\n",
    "    Parameters:\n",
    "    series (pd.Series): A pandas Series of datetime objects.\n",
    "\n",
    "    Returns:\n",
    "    str: A string representing the most common frequency (e.g., 'D' for days, 'H' for hours).\n",
    "    \"\"\"\n",
    "    # Drop NaN values to avoid errors in calculations\n",
    "    series = series.dropna()\n",
    "\n",
    "    # Calculate the differences between consecutive dates\n",
    "    diffs = series.diff().dropna()\n",
    "\n",
    "    # Calculate the most common frequency\n",
    "    freq = diffs.mode()[0]\n",
    "\n",
    "    # Convert the frequency to a string representation\n",
    "    series = series.dropna()\n",
    "\n",
    "    # Calculate the differences between consecutive dates\n",
    "    diffs = series.diff().dropna()\n",
    "\n",
    "    # Calculate the most common frequency\n",
    "    freq = diffs.mode()[0]\n",
    "\n",
    "    # Convert the frequency to a string representation\n",
    "    if freq == pd.Timedelta(days=1):\n",
    "        return 'D'  # Daily\n",
    "    elif freq >= pd.Timedelta(days=7):\n",
    "        return 'W'  # Weekly\n",
    "    elif freq >= pd.Timedelta(days=30):\n",
    "        return 'M'  # Monthly\n",
    "    elif freq >= pd.Timedelta(days=90):\n",
    "        return 'Q'  # Quartely\n",
    "    elif freq >= pd.Timedelta(days=365):\n",
    "        return 'A'  # Annually\n",
    "    else:\n",
    "        return freq  # Return the exact frequency if it's not a common one\n",
    "\n",
    "\n",
    "def Detections_(df, y_column, problem, date_col=None):\n",
    "    if date_col:\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "    if problem == \"timeseries\":\n",
    "        df.rename(columns={date_col: 'ds', y_column: 'y'}, inplace=True)\n",
    "        y_column = 'y'\n",
    "        df['y'] = df['y'].str.replace('[^0-9\\.]', '', regex=True)\n",
    "        df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "        df['y'] = df['y'].astype(float)\n",
    "\n",
    "    df = RemoveIDColumn.remove_high_cardinality_columns(df)\n",
    "    df = MissingValues().del_high_null_cols(df)\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    nulls_columns = MissingValues().detect_nulls(df)\n",
    "    cols_with_outliers = Outliers().detect_outliers(df)\n",
    "    df = Duplicates().handle_dub(df)\n",
    "    imbalance_detected = None\n",
    "    if problem == \"classification\":\n",
    "        imbalance_detected = HandlingImbalanceClasses().detect_class_imbalance(df, y_column)\n",
    "    df_without_y = df.drop(columns=[y_column])\n",
    "    low_variance_columns, low_variance_info = HandlingColinearity().detect_low_variance(df_without_y)\n",
    "\n",
    "    return df, nulls_columns, cols_with_outliers, imbalance_detected, low_variance_columns, categorical_columns\n",
    "\n",
    "\n",
    "def _process_data(df: pd.DataFrame, fill_na_dict: dict, outliers_methods_input: tuple,\n",
    "                  Norm_method: str) -> pd.DataFrame:\n",
    "    \"\"\"Handle missing values, outliers, normalization, and encoding.\"\"\"\n",
    "    df = MissingValues().handle_nan(df, fill_na_dict)\n",
    "    cols_with_outliers = Outliers().detect_outliers(df)\n",
    "    df = Outliers().handle_outliers(df, cols_with_outliers, outliers_methods_input)\n",
    "    df = DataNormalization().normalize_data(df, Norm_method)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def Cleaning(df, problem, y_column, fill_na_dict, outliers_methods_input, imb_instruction, Norm_method,\n",
    "             lowvariance_actions, encoding_dict, date_col=None):\n",
    "    if problem == \"timeseries\":\n",
    "        date_col = 'ds'\n",
    "        y_column = 'y'\n",
    "        frequency = calculate_date_frequency(df[date_col])\n",
    "        df.set_index('ds', inplace=True)\n",
    "        train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    elif problem == \"classification\":\n",
    "        train_data, test_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df[y_column])\n",
    "        train_data = train_data.reset_index(drop=True)\n",
    "        test_data = test_data.reset_index(drop=True)\n",
    "    else:\n",
    "        df['timestamp'] = df[date_col].astype('int64') / 10 ** 9  # Convert to UNIX timestamp in seconds\n",
    "        df['year'] = df[date_col].dt.year\n",
    "        df['month'] = df[date_col].dt.month\n",
    "        df['day'] = df[date_col].dt.day\n",
    "        df.drop(date_col, axis=1, inplace=True)\n",
    "        train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        train_data = train_data.reset_index(drop=True)\n",
    "        test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "    train_data = _process_data(train_data, fill_na_dict, outliers_methods_input, Norm_method)\n",
    "    test_data = _process_data(test_data, fill_na_dict, outliers_methods_input, Norm_method)\n",
    "\n",
    "    df_copy = pd.concat([train_data, test_data])\n",
    "    df_copy = df_copy.sort_index()\n",
    "    original_columns = set(df.columns)\n",
    "\n",
    "    # Remove co-linearity & low_variance\n",
    "    historical_df_without_y = df_copy.drop(columns=[y_column])\n",
    "    historical_df_without_y = HandlingColinearity().handle_low_variance(historical_df_without_y, lowvariance_actions)\n",
    "    historical_df_without_y = HandlingColinearity().handling_colinearity(historical_df_without_y)\n",
    "    historical_df_without_y[y_column] = df_copy[y_column]\n",
    "\n",
    "    # Update historical_df_copy with processed columns\n",
    "    df_copy = historical_df_without_y.copy()\n",
    "\n",
    "    # Identify removed columns\n",
    "    processed_columns = set(df_copy.columns)\n",
    "    removed_columns = list(original_columns - processed_columns)\n",
    "\n",
    "    # Remove identified columns from train_data and test_data\n",
    "    train_data = train_data.drop(columns=removed_columns)\n",
    "    test_data = test_data.drop(columns=removed_columns)\n",
    "    # if problem != \"timeseries\":\n",
    "    # not needed now\n",
    "    # meta_extractor, meta_features, best_models = extract_and_search_features(df_copy)\n",
    "\n",
    "    train_data = EncodeCategorical().Encode(train_data, encoding_dict)\n",
    "    test_data = EncodeCategorical().Encode(test_data, encoding_dict)\n",
    "\n",
    "    if imb_instruction:\n",
    "        train_data = HandlingImbalanceClasses().handle_class_imbalance(train_data, y_column, imb_instruction)\n",
    "        test_data = HandlingImbalanceClasses().handle_class_imbalance(test_data, y_column, imb_instruction)\n",
    "\n",
    "    df_copy = pd.concat([train_data, test_data])\n",
    "    df_copy = df_copy.sort_index()\n",
    "\n",
    "    if problem != \"timeseries\":\n",
    "        x_train = train_data.drop(columns=[y_column])\n",
    "        y_train = train_data[y_column]\n",
    "\n",
    "        # Split test_data into features and labels\n",
    "        x_test = test_data.drop(columns=[y_column])\n",
    "        y_test = test_data[y_column]\n",
    "\n",
    "        return x_train, y_train, x_test, y_test,\n",
    "    else:\n",
    "        return train_data, test_data, frequency\n",
    "\n",
    "\n",
    "def user_interaction(df, problem, y_column, date_col=None):\n",
    "    try:\n",
    "        df, nulls_columns, cols_with_outliers, imbalance, low_variance_columns, categorical_columns = Detections_(df,\n",
    "                                                                                                                  y_column,\n",
    "                                                                                                                  problem,\n",
    "                                                                                                                  date_col)\n",
    "\n",
    "        # Handling missing values\n",
    "        fill_na_dict = {}\n",
    "        if nulls_columns:\n",
    "            fill_na_dict = {col: 'auto' for col in nulls_columns}\n",
    "\n",
    "        # Handling outliers\n",
    "        outliers_method_input = ('z_score', 'auto', 3)\n",
    "        imb_instruction = \"auto\" if imbalance else None\n",
    "        Norm_method = \"auto\"\n",
    "        low_actions = {}\n",
    "        encoding_dict = {}\n",
    "        if categorical_columns:\n",
    "            encoding_dict = {col: 'auto' for col in categorical_columns}\n",
    "        if low_variance_columns:\n",
    "            low_actions = {col: 'auto' for col in low_variance_columns}\n",
    "\n",
    "        if problem != \"timeseries\":\n",
    "            x_train, y_train, x_test, y_test = Cleaning(df, problem, y_column, fill_na_dict, outliers_method_input,\n",
    "                                                        imb_instruction, Norm_method, low_actions, encoding_dict,\n",
    "                                                        date_col)\n",
    "            return x_train, y_train, x_test, y_test\n",
    "\n",
    "        else:\n",
    "            train_data, test_data, frequency = Cleaning(df, problem, y_column, fill_na_dict, outliers_method_input,\n",
    "                                                        imb_instruction, Norm_method, low_actions, encoding_dict,\n",
    "                                                        date_col)\n",
    "            return train_data, test_data, frequency\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error occurred: {ve}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:95] Reducing the number of initial configurations from 40 to 2 (max_ratio == 0.25).\n",
      "[INFO][abstract_initial_design.py:147] Using 2 initial design configurations and 0 additional configurations.\n",
      "let's start the optimization\n",
      "[WARNING][abstract_runner.py:134] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.\n",
      "[INFO][abstract_intensifier.py:515] Added config 0963f6 as new incumbent because there are no incumbents yet.\n",
      "[WARNING][abstract_runner.py:134] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pynisher\\pynisher.py:420\u001b[0m, in \u001b[0;36mPynisher.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mreceive_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    421\u001b[0m     response \u001b[38;5;241m=\u001b[39m receive_pipe\u001b[38;5;241m.\u001b[39mrecv()\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:329\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:878\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 878\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:810\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 810\u001b[0m     res \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m Bestmodelobj\u001b[38;5;241m.\u001b[39msplitTestData()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# print(Bestmodelobj.y_test1)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Bestmodelobj.Getincumbent()\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mBestmodelobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\FCSE\\6. Graduation project\\gitHub\\Auto_ML_Project\\backend\\autoAnalysisServer\\preprocessing_Scripts\\bestmodel.py:33\u001b[0m, in \u001b[0;36mBestmodel.TrainModel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrainModel\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 33\u001b[0m     incumbent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetincumbent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     HPOdict\u001b[38;5;241m=\u001b[39mincumbent\u001b[38;5;241m.\u001b[39mget_dictionary()\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblemtype \u001b[38;5;241m==\u001b[39mProblemType\u001b[38;5;241m.\u001b[39mCLASSIFICATION:\n",
      "File \u001b[1;32me:\\FCSE\\6. Graduation project\\gitHub\\Auto_ML_Project\\backend\\autoAnalysisServer\\preprocessing_Scripts\\bestmodel.py:29\u001b[0m, in \u001b[0;36mBestmodel.Getincumbent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGetincumbent\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# print(\"the ytrain is: \",self.y_train.head())\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     Facadee\u001b[38;5;241m=\u001b[39msmacClass\u001b[38;5;241m.\u001b[39mFacade(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblemtype,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoosenModels,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m---> 29\u001b[0m     incumbent\u001b[38;5;241m=\u001b[39m\u001b[43mFacadee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchooseFacade\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# print(incumbent)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m incumbent\n",
      "File \u001b[1;32me:\\FCSE\\6. Graduation project\\gitHub\\Auto_ML_Project\\backend\\autoAnalysisServer\\preprocessing_Scripts\\cashAlgorithm\\smacClass.py:282\u001b[0m, in \u001b[0;36mFacade.chooseFacade\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRegressionFacade()\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m ProblemType\u001b[38;5;241m.\u001b[39mTIME_SERIES:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTimeSeriesFacade\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m ProblemType\u001b[38;5;241m.\u001b[39mUNBALANCED:\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUnbalancedFacade()\n",
      "File \u001b[1;32me:\\FCSE\\6. Graduation project\\gitHub\\Auto_ML_Project\\backend\\autoAnalysisServer\\preprocessing_Scripts\\cashAlgorithm\\smacClass.py:309\u001b[0m, in \u001b[0;36mFacade.TimeSeriesFacade\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    306\u001b[0m scenario \u001b[38;5;241m=\u001b[39m Scenario(timeclassifier\u001b[38;5;241m.\u001b[39mconfigspace(), deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,trial_walltime_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m    307\u001b[0m smac \u001b[38;5;241m=\u001b[39m HyperparameterOptimizationFacade(scenario, timeclassifier\u001b[38;5;241m.\u001b[39mtrain, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m                                         callbacks\u001b[38;5;241m=\u001b[39m[CustomCallback()])\n\u001b[1;32m--> 309\u001b[0m incumbent \u001b[38;5;241m=\u001b[39m \u001b[43msmac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# print(incumbent)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m incumbent\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\smac\\facade\\abstract_facade.py:322\u001b[0m, in \u001b[0;36mAbstractFacade.optimize\u001b[1;34m(self, data_to_scatter)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_to_scatter must be None or dict with some elements, but got an empty dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 322\u001b[0m     incumbents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_to_scatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_to_scatter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\smac\\main\\smbo.py:304\u001b[0m, in \u001b[0;36mSMBO.optimize\u001b[1;34m(self, data_to_scatter)\u001b[0m\n\u001b[0;32m    300\u001b[0m     trial_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask()\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m# We submit the trial to the runner\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;66;03m# In multi-worker mode, SMAC waits till a new worker is available here\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdask_data_to_scatter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\smac\\runner\\abstract_serial_runner.py:22\u001b[0m, in \u001b[0;36mAbstractSerialRunner.submit_trial\u001b[1;34m(self, trial_info)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial_info: TrialInfo) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function submits a trial_info object in a serial fashion. As there is a single\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m     worker for this task, this interface can be considered a wrapper over the `run` method.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m        An object containing the configuration launched.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results_queue\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_info\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\smac\\runner\\abstract_runner.py:110\u001b[0m, in \u001b[0;36mAbstractRunner.run_wrapper\u001b[1;34m(self, trial_info, **dask_data_to_scatter)\u001b[0m\n\u001b[0;32m    107\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     status, cost, runtime, additional_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdask_data_to_scatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    118\u001b[0m     status \u001b[38;5;241m=\u001b[39m StatusType\u001b[38;5;241m.\u001b[39mCRASHED\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\smac\\runner\\target_function_runner.py:186\u001b[0m, in \u001b[0;36mTargetFunctionRunner.run\u001b[1;34m(self, config, instance, budget, seed, **dask_data_to_scatter)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 186\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_copy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     runtime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    188\u001b[0m     status \u001b[38;5;241m=\u001b[39m StatusType\u001b[38;5;241m.\u001b[39mSUCCESS\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\smac\\runner\\target_function_runner.py:259\u001b[0m, in \u001b[0;36mTargetFunctionRunner.__call__\u001b[1;34m(self, config, algorithm, algorithm_kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    247\u001b[0m     config: Configuration,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], \u001b[38;5;28mdict\u001b[39m]\n\u001b[0;32m    257\u001b[0m ):\n\u001b[0;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the algorithm, which is processed in the ``run`` method.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43malgorithm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pynisher\\pynisher.py:498\u001b[0m, in \u001b[0;36mPynisher.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m             receive_pipe\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    496\u001b[0m             send_pipe\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# Close the pipes\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     receive_pipe\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df1 =pd.read_csv(r\"daily-minimum-temperatures-in-me.csv\")\n",
    "problemtype1 = \"timeseries\"\n",
    "train_data, test_data,frequency = user_interaction(df1, problemtype1, \"Daily minimum temperatures\", date_col=\"Date\")\n",
    "choosenModels=[\"Arima\"]\n",
    "traindatax='lol'\n",
    "test_datax='loll'\n",
    "# print(test_data)\n",
    "Bestmodelobj = Bestmodel(ProblemType.TIME_SERIES,choosenModels,traindatax,traindatax,train_data,test_data,frequency)\n",
    "Bestmodelobj.splitTestData()\n",
    "# print(Bestmodelobj.y_test1)\n",
    "# Bestmodelobj.Getincumbent()\n",
    "Bestmodelobj.TrainModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:95] Reducing the number of initial configurations from 40 to 25 (max_ratio == 0.25).\n",
      "[INFO][abstract_initial_design.py:147] Using 24 initial design configurations and 0 additional configurations.\n",
      "let's start the optimization\n",
      "[INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.\n",
      "[INFO][abstract_intensifier.py:515] Added config 61f4fc as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 7d1035 and rejected config 61f4fc as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 3f9fd5 and rejected config 7d1035 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config d53524 and rejected config 3f9fd5 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "The incumbent is: {'Models': 'LR', 'regularizationStre': 0.07983951867558062}\n",
      "The incumbent loss is: 0.202247191011236\n",
      "The incumbent is: {'Models': 'LR', 'regularizationStre': 0.07983951867558062}\n",
      "The incumbent loss is: 0.202247191011236\n",
      "The incumbent is: {'Models': 'LR', 'regularizationStre': 0.07983951867558062}\n",
      "The incumbent loss is: 0.202247191011236\n",
      "The incumbent has remained the same for 30 trials.\n",
      "Stopping the optimization process.\n",
      "[INFO][smbo.py:224] A callback returned False. Abort is requested.\n",
      "[INFO][smbo.py:332] Shutting down because the stop flag was set.\n",
      "Model accuracy: 77.53%\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(r\"train.csv\")\n",
    "problemtype2 = \"classification\"\n",
    "choosenModels = [\"KNN\", \"LR\", \"RF\"]\n",
    "x_train, y_train, x_test, y_test = user_interaction(df2, problemtype2, \"Survived\", date_col=None)\n",
    "Bestmodelobj = Bestmodel(ProblemType.CLASSIFICATION, choosenModels, x_train,x_test,y_train,y_test)\n",
    "Bestmodelobj.splitTestData()\n",
    "# Bestmodelobj.Getincumbent()\n",
    "Bestmodelobj.TrainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Temp\\ipykernel_60348\\2759679421.py\", line 3, in <module>\n",
      "    x_train, y_train, x_test, y_test = user_interaction(df3, problemtype3, \"Calories\", date_col=\"Date\")\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Temp\\ipykernel_60348\\3285653845.py\", line 162, in user_interaction\n",
      "    df, nulls_columns, cols_with_outliers, imbalance, low_variance_columns, categorical_columns = Detections_(df,\n",
      "                                                                                                  ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Temp\\ipykernel_60348\\3285653845.py\", line 62, in Detections_\n",
      "    df = MissingValues().del_high_null_cols(df)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alaa\\Desktop\\AutoML\\Auto_ML_Project\\backend\\autoAnalysisServer\\preprocessing_Scripts\\similaritySearch\\functions.py\", line 143, in del_high_null_cols\n",
      "    df[col], status, date_message = self.fill_datetime_na(df[col])\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alaa\\Desktop\\AutoML\\Auto_ML_Project\\backend\\autoAnalysisServer\\preprocessing_Scripts\\similaritySearch\\functions.py\", line 268, in fill_datetime_na\n",
      "    print(\"messageeeeee\",message)\n",
      "                        ^^^^^^^\n",
      "UnboundLocalError: cannot access local variable 'message' where it is not associated with a value\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1428, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1319, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1172, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1087, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 969, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\Alaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\executing\\executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(r\"pulsedata.csv\")\n",
    "problemtype3 = \"regression\"\n",
    "x_train, y_train, x_test, y_test = user_interaction(df3, problemtype3, \"Calories\", date_col=\"Date\")\n",
    "choosenModels = ['LinearRegression', \"Lasso\"]\n",
    "Bestmodelobj = Bestmodel(ProblemType.REGRESSION, choosenModels, x_train,x_test,y_train,y_test)\n",
    "Bestmodelobj.splitTestData()\n",
    "# Bestmodelobj.Getincumbent()\n",
    "Bestmodelobj.TrainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"daily-minimum-temperatures-in-me.csv\"\n",
    "df =pd.read_csv(path)\n",
    "df.rename(columns={'Date': 'ds', 'Daily minimum temperatures': 'y'}, inplace=True)\n",
    "df['ds'] = pd.to_datetime(df['ds'], format='%m/%d/%Y')\n",
    "df['y'] = df['y'].str.replace('[^0-9\\.]', '', regex=True)\n",
    "df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "df['y'] = df['y'].astype(float)\n",
    "df.set_index('ds', inplace=True)\n",
    "split_date = pd.to_datetime('1990-12-15')\n",
    "train_data = df[df.index <= split_date]\n",
    "test_data = df[df.index > split_date]\n",
    "traindatax='lol'\n",
    "test_datax='loll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-01-01</th>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-02</th>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-03</th>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-04</th>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-05</th>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-11</th>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-12</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-13</th>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-14</th>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-15</th>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3634 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               y\n",
       "ds              \n",
       "1981-01-01  20.7\n",
       "1981-01-02  17.9\n",
       "1981-01-03  18.8\n",
       "1981-01-04  14.6\n",
       "1981-01-05  15.8\n",
       "...          ...\n",
       "1990-12-11  11.1\n",
       "1990-12-12  14.0\n",
       "1990-12-13  11.4\n",
       "1990-12-14  12.5\n",
       "1990-12-15  13.4\n",
       "\n",
       "[3634 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Models import SARIMAModel\n",
    "# sarimasmac(train, test, p, q, d, P, Q, D, s, freq='D')\n",
    "# results=SARIMAModel.Sarimasmac(train_data, test_data, 2, 0, 0, 3, 1, 3, 30, freq='D')\n",
    "# resul/ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:95] Reducing the number of initial configurations from 80 to 2 (max_ratio == 0.25).\n",
      "[INFO][abstract_initial_design.py:147] Using 2 initial design configurations and 0 additional configurations.\n",
      "let's start the optimization\n",
      "[INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.\n",
      "[WARNING][abstract_runner.py:134] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.\n",
      "[INFO][abstract_intensifier.py:515] Added config 31b9e5 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 04a5f9 and rejected config 31b9e5 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[WARNING][abstract_runner.py:134] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.\n",
      "[WARNING][abstract_runner.py:134] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.\n",
      "[INFO][abstract_intensifier.py:594] Added config e96d2b and rejected config 04a5f9 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[WARNING][abstract_runner.py:134] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.\n",
      "[WARNING][abstract_runner.py:134] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.\n",
      "[WARNING][abstract_runner.py:134] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.\n",
      "[WARNING][abstract_runner.py:134] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.\n",
      "The incumbent is: {'Models': 'Sarima', 'd': 1, 'p': 0, 'q': 2, 'sd': 0, 'sp': 0, 'sq': 1, 'ss': 30}\n",
      "The incumbent loss is: 23.06167266189422\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: inf\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 0\n",
      "Model MSE: 12.614792084692727\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    problemtype = ProblemType.TIME_SERIES\n",
    "    choosenModels=['Sarima']\n",
    "    Bestmodelobj = Bestmodel(problemtype,choosenModels,traindatax,traindatax,train_data,test_data)\n",
    "    Bestmodelobj.splitTestData()\n",
    "    # Bestmodelobj.Getincumbent()\n",
    "    Bestmodelobj.TrainModel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=Bestmodelobj.PredictModel(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990-12-16    13.043275\n",
       "1990-12-17     9.459163\n",
       "1990-12-18    11.359163\n",
       "1990-12-19    10.559163\n",
       "1990-12-20     8.959163\n",
       "1990-12-21    15.659163\n",
       "1990-12-22    12.859163\n",
       "1990-12-23    11.159163\n",
       "1990-12-24    11.759163\n",
       "1990-12-25    13.659163\n",
       "1990-12-26    13.559163\n",
       "1990-12-27     9.459163\n",
       "1990-12-28    15.359163\n",
       "1990-12-29    15.359163\n",
       "1990-12-30    13.359163\n",
       "1990-12-31    13.959163\n",
       "Freq: D, Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
